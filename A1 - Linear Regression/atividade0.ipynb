{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CPU device\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "xy = pd.read_csv(\"_data/bottle.csv\")\n",
    "\n",
    "xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve salinity and temperature columns\n",
    "x_raw = xy.iloc[:,5] # salinity \n",
    "y_raw = xy.iloc[:,6] # temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if there is any data missing\n",
    "print(f'Salinity missing data summation (%): {x_raw.isna().sum()/len(x_raw)*100:.3f} %')\n",
    "print(f'Temperature missing data summation (%): {y_raw.isna().sum()/len(y_raw)*100:.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill missing data with ffill\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if data was filled\n",
    "print(f'Salinity missing data summation: {x_raw.isna().sum()}')\n",
    "print(f'Temperature missing data summation: {y_raw.isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "x = np.array(x_raw).reshape(-1,1) # Temperature\n",
    "y = np.array(y_raw).reshape(-1,1) # Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split into train+validation and test sets using sklearn library\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize the input (x in [0,1])\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters (change them to see their influence in training)\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# DON'T CHANGE THIS\n",
    "input_size = 1 # Number of features\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create dataloaders to Pytorch models\n",
    "class Salinity(Dataset):\n",
    "    ''' Receive a dataset and preprocess to transform into data loaders\n",
    "    \n",
    "        Input:\n",
    "            x_data (float numpy array): input values\n",
    "            y_data (float numpy array): expected output value\n",
    "    '''\n",
    "    def __init__(self, x_data, y_data):\n",
    "        # TODO: complete the generator\n",
    "        \n",
    "        # YOUR CODE HERE (delete pass after filling with your code)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "train_dataset = Salinity(torch.from_numpy(x_train.astype(np.float32)), torch.from_numpy(y_train.astype(np.float32)))\n",
    "val_dataset = Salinity(torch.from_numpy(x_val.astype(np.float32)), torch.from_numpy(y_val.astype(np.float32)))\n",
    "test_dataset = Salinity(torch.from_numpy(x_test.astype(np.float32)), torch.from_numpy(y_test.astype(np.float32)))\n",
    "\n",
    "# TODO: complete the dataloader (see https://pytorch.org/docs/stable/data.html)\n",
    "train_loader = None # YOUR CODE HERE\n",
    "val_loader = None # YOUR CODE HERE\n",
    "test_loader = None # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build the neural network architecture for linear regression\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # TODO: complete with the Neural Network architecture (set up the linear layer)\n",
    "        \n",
    "        # YOUR CODE HERE (delete pass after filling with your code)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: complete the forward method\n",
    "        \n",
    "        # YOUR CODE HERE (delete pass after filling with your code)\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the method\n",
    "model = None # YOUR CODE HERE\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "\n",
    "# TODO: complete with the loss function (hint: use Mean Square Error - MSE) \n",
    "criterion = None # YOUR CODE HERE\n",
    "\n",
    "# TODO: complete with the optimizer (hint: use Stochastic Gradient Descent -SGD)\n",
    "optimizer = None # YOUR CODE HERE\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations\n",
    "for e in tqdm(range(1, num_epochs+1)):\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        # alloacate to GPU or CPU\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        \n",
    "        # clean the gradients\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # TODO: coomplete the forward pass\n",
    "        y_train_pred = None # YOUR CODE HERE      \n",
    "        train_loss = None # YOUR CODE HERE\n",
    "        \n",
    "        # TODO: complete the backward pass\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # TODO: complete the weight update\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # clean the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch: {e}, Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference \n",
    "\n",
    "# transform into tensor\n",
    "x = torch.from_numpy(x_test.astype(np.float32))\n",
    "\n",
    "# prediction\n",
    "predicted = model(x).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# sklearn's Least Square Method\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x_test, y_pred , label='Least Square') # Least Square Method approach\n",
    "plt.plot(x_test, predicted, label='Neural Network') # Neural Network approach\n",
    "plt.xlabel('Salinity')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
